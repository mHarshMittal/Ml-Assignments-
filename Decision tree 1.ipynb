{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444924c5-48f5-4281-bd30-e05270829a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d4aa08c-295b-4983-84bb-9f15e792bf5d",
   "metadata": {},
   "source": [
    "Q3. Decision Tree Classifier for Binary Classification\n",
    "Application:\n",
    "\n",
    "Binary Classification Problem: Example - Classifying emails as spam or not spam.\n",
    "Steps:\n",
    "\n",
    "Data Preparation: Prepare the dataset with features (e.g., email content) and binary labels (spam or not spam).\n",
    "\n",
    "Training:\n",
    "\n",
    "The decision tree will split the dataset at each node to separate spam from not spam based on features (e.g., presence of specific words).\n",
    "The tree continues to split until it achieves a stopping criterion or all data points in a node belong to the same class.\n",
    "Prediction:\n",
    "\n",
    "For a new email, the decision tree will navigate through nodes based on the emailâ€™s features and reach a leaf node that indicates the class label (spam or not spam)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b4a71df-21b4-4a28-b812-4cf0e289841f",
   "metadata": {},
   "source": [
    "Q4. Geometric Intuition Behind Decision Tree Classification\n",
    "Geometric Intuition:\n",
    "\n",
    "Partitioning Space:\n",
    "\n",
    "Each decision tree split creates a decision boundary in the feature space.\n",
    "For each split, the feature space is divided into regions where a particular class is predominant.\n",
    "Regions:\n",
    "\n",
    "Each leaf node of the decision tree corresponds to a region in the feature space where the instances are classified into a specific class.\n",
    "The decision boundaries are axis-aligned (parallel to feature axes), which can result in a piecewise constant approximation of the decision surface.\n",
    "Making Predictions:\n",
    "\n",
    "For a given instance, the decision tree classifies it based on which region it falls into, determined by traversing the tree from the root to a leaf node.\n",
    "Q5. Confusion Matrix and Its Use\n",
    "Definition:\n",
    "\n",
    "A confusion matrix is a table used to evaluate the performance of a classification model by comparing the predicted and actual class labels.\n",
    "Components:\n",
    "\n",
    "True Positives (TP): Correctly predicted positive cases.\n",
    "True Negatives (TN): Correctly predicted negative cases.\n",
    "False Positives (FP): Incorrectly predicted positive cases.\n",
    "False Negatives (FN): Incorrectly predicted negative cases."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8845832-d05e-433c-8604-5332ae67526c",
   "metadata": {},
   "source": [
    "Q6. Example of Confusion Matrix and Metrics Calculation\n",
    "Example:\n",
    "\n",
    "Suppose the confusion matrix is:\n",
    "50   10\n",
    "5    35\n",
    "50\n",
    "5\n",
    "  \n",
    "10\n",
    "35\n",
    "\n",
    " \n",
    "True Positives (TP) = 35\n",
    "True Negatives (TN) = 50\n",
    "False Positives (FP) = 10\n",
    "False Negatives (FN) = 5\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a956046-f5a5-4e3d-913c-e3bd42922598",
   "metadata": {},
   "source": [
    "Q7. Choosing the Appropriate Evaluation Metric\n",
    "Factors to Consider:\n",
    "\n",
    "Class Imbalance: Precision and recall are crucial when dealing with imbalanced datasets.\n",
    "Business Objectives: Align the metric with the specific goals (e.g., minimizing false positives or false negatives).\n",
    "Model Performance: Use multiple metrics to get a comprehensive view of model performance.\n",
    "Example:\n",
    "\n",
    "For a medical diagnosis problem where missing a positive case (false negative) is critical, recall would be prioritized.\n",
    "Q8. Example Where Precision Is Most Important\n",
    "Example:\n",
    "\n",
    "Spam Detection in Email: Precision is crucial to minimize the number of legitimate emails wrongly classified as spam (false positives).\n",
    "Reason:\n",
    "\n",
    "High precision ensures that emails marked as spam are actually spam, reducing inconvenience to users who may lose important emails.\n",
    "Q9. Example Where Recall Is Most Important\n",
    "Example:\n",
    "\n",
    "Disease Screening: In a screening test for a serious disease, recall is crucial to identify as many positive cases as possible, even if it means more false positives.\n",
    "Reason:\n",
    "\n",
    "High recall ensures that most patients with the disease are detected, which is important for early intervention and treatment.\n",
    "These explanations and examples should help you understand the concepts and their application in classification problems. If you need further clarification or additional details, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff789f3-e047-4e6e-b286-c5bf0aba725f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
