{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5f3c13a0-8a5a-47fd-9f95-6ab9bbe85ede",
   "metadata": {},
   "source": [
    "Q1. What is Elastic Net Regression and How Does It Differ from Other Regression Techniques?\n",
    "Elastic Net Regression:\n",
    "\n",
    "Definition: Elastic Net Regression combines L1 (Lasso) and L2 (Ridge) regularization penalties. It aims to benefit from both Lasso's feature selection and Ridge's coefficient shrinkage."
   ]
  },
  {
   "cell_type": "raw",
   "id": "96557c25-4d04-4f14-af6c-236b0e175d64",
   "metadata": {},
   "source": [
    "Differences from Other Techniques:\n",
    "\n",
    "Ridge Regression: Uses only L2 regularization (shrinks coefficients but does not set any to zero).\n",
    "Lasso Regression: Uses only L1 regularization (can set some coefficients to zero for feature selection).\n",
    "Elastic Net: Combines both L1 and L2 penalties, providing a balance between feature selection and coefficient shrinkage."
   ]
  },
  {
   "cell_type": "raw",
   "id": "45cbd87b-77c1-46d5-93bf-1e79eb6e7350",
   "metadata": {},
   "source": [
    "Q2. Choosing the Optimal Values of the Regularization Parameters for Elastic Net Regression\n",
    "Methods:\n",
    "\n",
    "Grid Search with Cross-Validation: Evaluate different values for both λ₁ and λ₂ using k-fold cross-validation.\n",
    "Random Search: Sample from a range of values for λ₁ and λ₂ to find the optimal combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44b360f-258a-41d6-a53d-652a4f59b422",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable ellipsis object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElasticNetCV\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Elastic Net Regression with Cross-Validation to find optimal λ₁ and λ₂\u001b[39;00m\n\u001b[1;32m      7\u001b[0m elastic_net_cv \u001b[38;5;241m=\u001b[39m ElasticNetCV(alphas\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m10.0\u001b[39m], l1_ratio\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.9\u001b[39m], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable ellipsis object"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Example data\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# Elastic Net Regression with Cross-Validation to find optimal λ₁ and λ₂\n",
    "elastic_net_cv = ElasticNetCV(alphas=[0.01, 0.1, 1.0, 10.0], l1_ratio=[0.1, 0.5, 0.9], cv=5)\n",
    "elastic_net_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal λ₁:\", elastic_net_cv.alpha_)\n",
    "print(\"Optimal l1_ratio:\", elastic_net_cv.l1_ratio_)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e1a5e7a-96b4-4b16-9e99-6ef3595ed3f5",
   "metadata": {},
   "source": [
    "Q3. Advantages and Disadvantages of Elastic Net Regression\n",
    "Advantages:\n",
    "\n",
    "Feature Selection and Shrinkage: Combines benefits of Lasso (feature selection) and Ridge (shrinkage).\n",
    "Handles Multicollinearity: Effective when predictors are highly correlated.\n",
    "Disadvantages:\n",
    "\n",
    "Complexity: Requires tuning of two parameters (λ₁ and λ₂).\n",
    "Less Intuitive: Can be more complex to interpret compared to Ridge or Lasso alone.\n",
    "Q4. Common Use Cases for Elastic Net Regression\n",
    "Use Cases:\n",
    "\n",
    "High-Dimensional Data: When the number of features is much larger than the number of samples.\n",
    "Feature Selection: When you want to perform feature selection while also accounting for multicollinearity.\n",
    "Gene Expression Analysis: In genomics, where many predictors are correlated and feature selection is needed.\n",
    "Q5. Interpreting the Coefficients in Elastic Net Regression\n",
    "Interpretation:\n",
    "\n",
    "Coefficients: Reflect the combined effect of both L1 and L2 penalties. Non-zero coefficients indicate features that have a significant effect on the response variable. The magnitude and direction of coefficients are influenced by both regularization terms.\n",
    "Q6. Handling Missing Values in Elastic Net Regression\n",
    "Approach:\n",
    "\n",
    "Imputation: Fill in missing values using techniques like mean imputation, median imputation, or more sophisticated methods like K-nearest neighbors or regression imputation.\n",
    "Use of Models: Some libraries and methods handle missing values internally, but it's generally best practice to preprocess data by imputing missing values before applying Elastic Net Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39930fdc-66c6-474e-b04d-fbc3f3fc3888",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# or strategy='median'\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_imputed \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Example data\n",
    "imputer = SimpleImputer(strategy='mean')  # or strategy='median'\n",
    "X_imputed = imputer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c403211a-ce49-4ac0-a88c-da3a71b0ef55",
   "metadata": {},
   "source": [
    "Q7. Using Elastic Net Regression for Feature Selection\n",
    "Feature Selection:\n",
    "\n",
    "Elastic Net performs implicit feature selection by shrinking some coefficients to zero (L1 penalty) while penalizing large coefficients (L2 penalty). Features with non-zero coefficients are selected, while those with zero coefficients are excluded from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301bc74c-4c78-41c7-94e0-ac287eea3e64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Fit Elastic Net model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m elastic_net \u001b[38;5;241m=\u001b[39m ElasticNet(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m elastic_net\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Coefficients\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mwhere(elastic_net\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Fit Elastic Net model\n",
    "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Selected features:\", np.where(elastic_net.coef_ != 0))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "410ae2e4-c2cc-4de7-a6a8-881ae79dce7d",
   "metadata": {},
   "source": [
    "Q8. Pickling and Unpickling a Trained Elastic Net Regression Model in Python\n",
    "Pickling:\n",
    "\n",
    "Purpose: To save and load models for reuse without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b54c3c4-c9d4-48a5-8ed3-ed36f07efa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open('elastic_net_model.pkl', 'wb') as file:\n",
    "    pickle.dump(elastic_net, file)\n",
    "\n",
    "# Load the trained model\n",
    "with open('elastic_net_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a54eb676-c24c-43dc-93f9-c36d4bf8fafb",
   "metadata": {},
   "source": [
    "Q9. Purpose of Pickling a Model in Machine Learning\n",
    "Purpose:\n",
    "\n",
    "Persistence: Pickling allows you to save a trained model to disk so that you can load and reuse it without retraining, making the deployment of models easier and more efficient.\n",
    "Sharing: Facilitates sharing of models across different environments or among team members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf198e-874c-4ae3-84c8-192a6ebc1492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
