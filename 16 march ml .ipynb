{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ec044ae6-59d5-4591-bc58-04a5ab1b7307",
   "metadata": {},
   "source": [
    "Ml assignment -2 16 march"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d16177c7-569d-426f-88db-34eb97a913fa",
   "metadata": {},
   "source": [
    "\n",
    "Q1: Overfitting means the model learns the training data too well, even the noise, leading to poor predictions on new data. Underfitting is when the model is too simple to capture the pattern in the data, also resulting in poor predictions.\n",
    "\n",
    "To fix overfitting, use techniques like using more data, simplifying the model, or using validation checks. For underfitting, try using a more complex model or adding more features.\n",
    "\n",
    "Q2: To stop overfitting, you can try methods like using more data, making the model simpler, or using techniques that prevent it from focusing too much on the training data.\n",
    "\n",
    "Q3: Underfitting happens when the model is too basic to understand the data properly. This can occur when the model is too simple or when there isn't enough data to learn from.\n",
    "\n",
    "Q4: Bias-variance tradeoff is a balance between how much a model can learn and how much it should stick to what it already knows. If a model has too much bias, it might not learn enough; if it has too much variance, it might learn too much from the data, even the noise.\n",
    "\n",
    "Q5: To check if a model is overfitting or underfitting, you can use methods like cross-validation, learning curves, or looking at the difference between predicted and actual values.\n",
    "\n",
    "Q6: Bias is when a model assumes things that might not be true, while variance is when the model is too sensitive to small changes in the data. High bias models are too simple, like guessing all values are the same; high variance models are too complex, like memorizing the training data.\n",
    "\n",
    "Q7: Regularization is a way to prevent overfitting by adding rules to the model to keep it from getting too complex. This can include techniques like penalizing big coefficients or randomly dropping parts of the model during training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
