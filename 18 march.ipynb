{
 "cells": [
  {
   "cell_type": "raw",
   "id": "054b9927-6e4b-4a14-8c5b-0468ce6d66c6",
   "metadata": {},
   "source": [
    "18 march assignment\n",
    "Feature Engineering-2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2189cf81-cbf0-4ef0-88bc-c4f5716bbd26",
   "metadata": {},
   "source": [
    "Q1. The Filter method in feature selection is a technique where features are selected based on their statistical properties, such as correlation with the target variable or variance. It works by evaluating each feature independently of the others and selecting the most relevant ones according to predefined criteria.\n",
    "\n",
    "Q2. The Wrapper method, unlike the Filter method, evaluates the performance of a selected set of features using a predictive model. It involves selecting subsets of features, training a model on each subset, and then selecting the best performing subset based on model performance metrics.\n",
    "\n",
    "Q3. Some common techniques used in Embedded feature selection methods include Lasso Regression, Ridge Regression, Elastic Net, and Decision Trees. These methods incorporate feature selection as part of the model training process, effectively selecting the most relevant features while building the model.\n",
    "\n",
    "Q4. Some drawbacks of using the Filter method for feature selection include the possibility of missing important feature interactions, selecting redundant or irrelevant features, and not considering the impact of feature subsets on the overall model performance.\n",
    "\n",
    "Q5. The Filter method is preferred over the Wrapper method for feature selection when dealing with a large dataset with a high number of features, as it is computationally less expensive and quicker to implement compared to the Wrapper method.\n",
    "\n",
    "Q6. To choose the most pertinent attributes for the customer churn model using the Filter Method in the telecom company project, you could start by calculating statistical measures such as correlation coefficients, mutual information, or variance with the target variable. Features with high scores based on these metrics can be selected for further analysis and model building.\n",
    "\n",
    "Q7. In the soccer match prediction project, you can use Embedded methods like Lasso Regression or Decision Trees to select the most relevant features. These methods will automatically select features that contribute the most to the predictive performance of the model while training it, thereby eliminating the need for separate feature selection steps.\n",
    "\n",
    "Q8. For the house price prediction project, you can utilize the Wrapper method by employing techniques like Recursive Feature Elimination (RFE) with a cross-validated model performance metric. RFE works by recursively removing the least important features and training the model on the remaining ones until the optimal set of features is selected based on model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d9823-3748-4b95-acc3-48a2f569e9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
